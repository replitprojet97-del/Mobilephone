# ğŸ›’ LUXIO - Scripts de Scraping Node.js

## Vue d'ensemble

Ce projet utilise maintenant un systÃ¨me de scraping **100% Node.js** pour la collecte de donnÃ©es de smartphones depuis Fnac.com. Le systÃ¨me Python prÃ©cÃ©dent a Ã©tÃ© complÃ¨tement converti pour une compatibilitÃ© totale avec Vercel et un dÃ©ploiement serverless.

## ğŸš€ FonctionnalitÃ©s

- **Scraping automatique** des smartphones depuis Fnac.com
- **DonnÃ©es de test** de fallback en cas d'Ã©chec du scraping
- **API intÃ©grÃ©e** pour l'utilisation depuis le frontend
- **Scripts manuels** pour la mise Ã  jour des donnÃ©es
- **Compatible Vercel** - pas de dÃ©pendances serveur persistant

## ğŸ“‹ Scripts disponibles

### Scraping manuel
```bash
# Lancer le scraping et sauvegarder dans smartphones.json
npm run scrape

# Alternative (mÃªme commande)
npm run scrape:phones
```

### API de scraping
L'endpoint `/api/scraper` est automatiquement disponible et utilise la mÃªme logique :
```bash
# Test via curl
curl http://localhost:5000/api/scraper

# RÃ©ponse JSON avec les smartphones trouvÃ©s
```

## ğŸ—ï¸ Architecture technique

### Fichiers crÃ©Ã©s
- `scripts/fnac-scraper.js` - Script principal de scraping
- `api/scraper.js` - Endpoint API pour l'usage frontend
- `smartphones.json` - Fichier de donnÃ©es gÃ©nÃ©rÃ© automatiquement

### DÃ©pendances Node.js utilisÃ©es
- **axios** - RequÃªtes HTTP (remplace `requests` Python)
- **cheerio** - Parsing HTML (remplace `BeautifulSoup` Python)
- **fs** - Gestion des fichiers JSON

### Logique de scraping
1. **Extraction** depuis la page Fnac des smartphones
2. **Parsing HTML** avec des sÃ©lecteurs CSS robustes
3. **Extraction de mÃ©tadonnÃ©es** : marque, modÃ¨le, prix, stockage, image
4. **Fallback automatique** vers des donnÃ©es de test en cas d'erreur
5. **Sauvegarde** au format JSON

## ğŸ”§ Utilisation avant dÃ©ploiement

### DÃ©veloppement local
```bash
# 1. Lancer le scraping pour mettre Ã  jour les donnÃ©es
npm run scrape

# 2. Lancer le serveur de dÃ©veloppement
npm start

# 3. Tester l'API
curl http://localhost:5000/api/scraper
```

### Workflow de dÃ©ploiement Vercel
```bash
# 1. Scraping des derniÃ¨res donnÃ©es avant dÃ©ploiement
npm run scrape

# 2. Commit des nouvelles donnÃ©es
git add smartphones.json
git commit -m "Update smartphones data"

# 3. DÃ©ploiement
npm run deploy
```

## ğŸ›¡ï¸ Gestion d'erreurs

Le systÃ¨me inclut une gestion robuste des erreurs :
- **Erreurs rÃ©seau** â†’ Utilisation des donnÃ©es de test
- **Erreurs de parsing** â†’ Log des erreurs + fallback
- **Site inaccessible** â†’ DonnÃ©es de test automatiques
- **Timeout** â†’ Limite de 10 secondes + fallback

## ğŸ“Š Format des donnÃ©es

```json
{
  "title": "iPhone 15 Pro 128 GB Titanium Blue",
  "brand": "Apple",
  "model": "15 Pro", 
  "storage": "128 GB",
  "price": "1 229,00 â‚¬",
  "url": "https://www.fnac.com/...",
  "image_url": "https://static.fnac-static.com/...",
  "source": "Fnac" // ou "Test Data"
}
```

## âš™ï¸ Configuration

### Headers HTTP
Le scraper utilise des headers rÃ©alistes pour Ã©viter les blocages :
- User-Agent moderne Chrome
- Accept-Language franÃ§ais
- Referer Fnac.com
- Cache-Control appropriÃ©

### Limites et performances

#### API (serverless/Vercel)
- **8 produits maximum** par appel (Ã©viter les timeouts serverless)
- **Pas de dÃ©lai** artificiel (mode rapide)
- **Timeout** de 10 secondes par requÃªte
- **Fallback immÃ©diat** aux donnÃ©es de test

#### CLI (npm run scrape)
- **20 produits maximum** par scraping
- **DÃ©lais respectueux** entre les requÃªtes (1-2 secondes)  
- **Sauvegarde** dans smartphones.json
- **Fallback automatique** si aucun produit trouvÃ©

## ğŸš€ CompatibilitÃ© Vercel

Le systÃ¨me est entiÃ¨rement compatible Vercel :
- âœ… **Pas de serveur persistant** requis
- âœ… **Functions serverless** uniquement
- âœ… **Scripts manuels** pour mise Ã  jour des donnÃ©es
- âœ… **Pas de dÃ©pendances systÃ¨me** (Python, pip, etc.)
- âœ… **Node.js natif** seulement

## ğŸ”„ Migration depuis Python

La conversion Python â†’ Node.js conserve :
- âœ… **MÃªme logique** de scraping
- âœ… **MÃªmes sÃ©lecteurs** CSS
- âœ… **MÃªme format** de donnÃ©es de sortie
- âœ… **MÃªme gestion** d'erreurs
- âœ… **MÃªmes donnÃ©es** de test de fallback

## ğŸ“ Logs et debugging

```bash
# Voir les logs dÃ©taillÃ©s du scraping
npm run scrape

# Test de l'API avec logs
curl -v http://localhost:5000/api/scraper
```

Les logs incluent :
- Nombre de produits trouvÃ©s
- Titre de chaque smartphone extrait
- Source des donnÃ©es (scraped/test_data)
- Erreurs de scraping avec dÃ©tails